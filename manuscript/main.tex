\documentclass[12pt]{article}

\usepackage{amsmath, amsthm, amssymb}
\usepackage{amssymb}
\usepackage{bbm}

\usepackage[hidelinks]{hyperref}
\usepackage{cleveref}
\usepackage{url}

%%% For figures
\usepackage{graphicx}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}

%%% For tables
\usepackage[table]{xcolor}

%specifying table and figure packages
\usepackage{caption}

\usepackage[T1]{fontenc}
\usepackage[all]{xy}
\usepackage[inline]{enumitem}

\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{remark}{Remark}
\newtheorem{example}{Example}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}

\newcommand{\mattia}[1]{\textcolor{cyan}{#1}}
\newcommand{\pietro}[1]{\textcolor{teal}{#1}}
\newcommand{\Ban}{{\mathbf{Ban}}}
\newcommand{\Top}{{\mathbf{Top}}}
\newcommand{\forget}{{\textnormal{forget}}}
\newcommand{\free}{{\textnormal{free}}}
\newcommand{\pt}{{\textnormal{pt}}}
\newcommand{\Hom}{{\textnormal{Hom}}}
\newcommand{\End}{{\textnormal{End}}}
\newcommand{\Fun}{{\textnormal{Fun}}}
\newcommand{\Aut}{{\textnormal{Aut}}}
\newcommand{\Obj}{{\textnormal{Obj}}}
\newcommand{\id}{{\textnormal{id}}}
\newcommand{\Morph}{{\textnormal{Morph}}}
\newcommand{\Set}{{\mathbf{Set}}}
\newcommand{\Mon}{{\mathbf{Mon}}}
\newcommand{\Cat}{{\mathbf{C}}}
\newcommand{\DCat}{{\mathbf{D}}}
\newcommand{\JCat}{{\mathbf{J}}}
\newcommand{\LCat}{{\mathbf{L}}}
\newcommand{\range}[2]{{\{{#1}, \dots,{#2}\}}}
\newcommand{\anon}{{\,\mbox{-}\,}}

\crefname{diagram}{diag.}{diags.}
\Crefname{diagram}{Diagram}{Diagrams}
\creflabelformat{diagram}{#2(#1)#3}

\title{Weight sharing via dependent products}
\author{
    Pietro Vertechi \and Mattia G. Bergomi
}
\date{}
\begin{document}
\maketitle
\begin{abstract}
\end{abstract}

\section{Architectures in sets}

We begin by giving an abstract definition of {\em architecture}.

\begin{definition}\label{def:architecture}
    An {\em architecture} is a natural transformation from a comonad to an endofunctor. More explicitly, given a category $\DCat$, an {\em architecture} on $\DCat$ is composed of the following data:
    \begin{itemize}
        \item a comonad $T$ on $\DCat$,
        \item an endofunctor $S \colon \DCat \rightarrow \DCat$,
        \item a natural transformation $\eta \colon T \rightarrow S$.
    \end{itemize}
    % An architecture $(\DCat, T, S, \eta)$ is {\em valid} if the following conditions are met:
    % \begin{itemize}
    %     \item $\DCat$ has finite products,
    %     \item for all $(X, +)$ commutative monoid in $\DCat$ \pietro{meglio introdurre la categoria lineare a parte}, and for all
    %         \begin{equation*}
    %             f \colon SX \rightarrow X,
    %         \end{equation*}
    %         the composition
    %         \begin{equation*}
    %             f \circ \eta_X \colon TX \rightarrow X
    %         \end{equation*}
    %         is a {\em machine}~\cite{2020arXiv200702777V} in the Kleisli category $\DCat_T$.
    % \end{itemize}
\end{definition}

This is sufficient to give notions of composability, equivariance, and locality. In the reminder of the section, we will first give a broad class of architectures. Then, we will consider a simpler special case and show that it is sufficient to recover, among other examples, classical recurrent and convolutional neural networks. Here we propose a simple technique to define architectures in the category of sets. The following section will generalize this construction to locally Cartesian closed categories.

\begin{theorem}\label{thm:categorical_architecture}
    Let $\JCat$ be a small category. Let $\tilde M \subseteq \Morph(\JCat)$ be a subset of morphisms. $\JCat$ and $\tilde M$ induce an architecture on $\Set$, which we call a {\em categorical architecture}. 
\end{theorem}

\begin{proof}
    Let $s, t\colon M \rightarrow O$ be the source and target maps from the set of morphisms $M$ to the set of objects $O$. Then $t_*s^*\colon \Set/O \rightarrow \Set/O$ is a monad~\cite[Thm.~V.8.2]{Mac_Lane_1994}. As $\Set$ is locally Cartesian closed, $s^*$ has a right adjoint $s_!$, hence we can consider $s_!t^*$. As $T = s_!t^*$ is the right adjoint of the monad $t_*s^*$, it is a comonad. $T$ can be spelled out explicitly as follows. Given a map of sets $p\colon E \rightarrow O$, we have
    \begin{equation*}
        TE = \coprod_{o \in O} \, \, \prod_{m \in t^{-1}(o)} p^{-1}(s(m))
    \end{equation*}
    equipped with the obvious map $TE \rightarrow O$.
    We can then define
    \begin{equation*}
        SE = \coprod_{o \in O} \, \, \prod_{m \in t^{-1}(o)\cap \tilde M} p^{-1}(s(m)).
    \end{equation*}
    Projections on the product induce a natural transformation $\eta\colon T\ \rightarrow S$.
\end{proof}

Let $(P, \preceq)$ be a preorder, and let $F\colon P^{op} \rightarrow \Mon$ be a contravariant functor from $P$ to the category of monoids. Then they induce a small category with
\begin{equation*}
    \Hom(p, q) = \begin{cases}
        P(p) &\text{ if } p \preceq q,\\
        \emptyset &\text{ otherwise.}
    \end{cases}
\end{equation*}
\pietro{Spiegare che $F$ contiene gli endomorfismi sopra ogni oggetto, ma anche un modo per spostarsi.}

\section{Architectures in quasitopoi}

Same as above but in an arbitrary quasitopos.
\Cref{thm:categorical_architecture} holds as is, with internal categories in the quasitopos. Monoids becomes $F \rightarrow O \in \Cat/O$. Preorder is $R \subseteq O \times O$ (strong mono). $R$ induces a monad on $\Cat/O$ (always~\cite[Thm.~V.8.2]{Mac_Lane_1994}). We need an algebra in $\Mon(\Cat/O)$ for that monad. It is a bit worrying that it does not preserve products.

As examples, distance spaces, sequential spaces, etc.

\section{Comonadic machines}

Show how it's possible to obtain a machine from an architecture.

\section{Recurrent and convolutional neural networks}

Monoids can be considered as categories with one object. Let us consider the category corresponding to $\mathbb N$. Let $M$ be the set containing only the generator morphism. Then the above construction recovers recurrent neural networks. Analogously, considering $\mathbb N \times \mathbb N$ we obtain convolutional neural networks, where $M$ denotes the shape of the filter.
\pietro{TODO: mention 2 objects for conv, and strides!}
\pietro{Maybe also do functors, to generalize GENEO? Somehow discuss continuous version?}

\section{Novel architectures}

Here, we explore the scenario where the category $\Cat$ has more than one object.
\pietro{TODO: figure out a good application.}
\pietro{Mention partial symmetries because of non-composability.}

\bibliographystyle{abbrv}
\bibliography{References}

\end{document}
